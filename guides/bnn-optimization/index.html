<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="ie=edge"><meta name=description content="An Open-Source Library for Training Binarized Neural Networks"><link href=https://larq.dev/guides/bnn-optimization/ rel=canonical><meta name=author content=Plumerai><meta name=lang:clipboard.copy content="Copy to clipboard"><meta name=lang:clipboard.copied content="Copied to clipboard"><meta name=lang:search.language content=en><meta name=lang:search.pipeline.stopwords content=True><meta name=lang:search.pipeline.trimmer content=True><meta name=lang:search.result.none content="No matching documents"><meta name=lang:search.result.one content="1 matching document"><meta name=lang:search.result.other content="# matching documents"><meta name=lang:search.tokenizer content=[\s\-]+><link rel="shortcut icon" href=../../assets/images/favicon.png><meta name=generator content="mkdocs-1.0.4, mkdocs-material-4.4.0"><title>Training BNNs - Larq</title><link rel=stylesheet href=../../assets/stylesheets/application.0284f74d.css><link rel=stylesheet href=../../assets/stylesheets/application-palette.01803549.css><meta name=theme-color content=#2196f3><script src=../../assets/javascripts/modernizr.74668098.js></script><link href=https://fonts.gstatic.com rel=preconnect crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono&display=fallback"><style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style><link rel=stylesheet href=../../assets/fonts/material-icons.css><link rel=stylesheet href=../../custom.css></head> <body dir=ltr data-md-color-primary=blue data-md-color-accent=blue> <svg class=md-svg> <defs> <svg xmlns=http://www.w3.org/2000/svg width=416 height=448 viewbox="0 0 416 448" id=__github><path fill=currentColor d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg> </defs> </svg> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay data-md-component=overlay for=__drawer></label> <a href=#the-problem-with-sgd-in-bnns tabindex=1 class=md-skip> Skip to content </a> <header class=md-header data-md-component=header> <nav class="md-header-nav md-grid"> <div class=md-flex> <div class="md-flex__cell md-flex__cell--shrink"> <a href=https://larq.dev/ title=Larq class="md-header-nav__button md-logo"> <i class=md-icon>developer_board</i> </a> </div> <div class="md-flex__cell md-flex__cell--shrink"> <label class="md-icon md-icon--menu md-header-nav__button" for=__drawer></label> </div> <div class="md-flex__cell md-flex__cell--stretch"> <div class=md-flex__ellipsis data-md-component=title> <span class=md-header-nav__topic> <nav class="md-tabs__inner md-grid"> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../.. title=Learn class="md-tabs__link md-tabs__link--active"> Learn </a> </li> <li class=md-tabs__item> <a href=../../api/layers/ title=API class=md-tabs__link> API </a> </li> <li class=md-tabs__item> <a href=../../models/ title=Models class=md-tabs__link> Models </a> </li> <li class=md-tabs__item> <a href=../../papers/ title=Community class=md-tabs__link> Community </a> </li> <li class=md-tabs__item> <a href=../../about/ title="Why Larq?" class=md-tabs__link> Why Larq? </a> </li> </ul> </nav> </span> </div> </div> <div class="md-flex__cell md-flex__cell--shrink"> <label class="md-icon md-icon--search md-header-nav__button" for=__search></label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=query data-md-state=active> <label class="md-icon md-search__icon" for=__search></label> <button type=reset class="md-icon md-search__icon" data-md-component=reset tabindex=-1> &#xE5CD; </button> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=result> <div class=md-search-result__meta> Type to start searching </div> <ol class=md-search-result__list></ol> </div> </div> </div> </div> </div> </div> <div class="md-flex__cell md-flex__cell--shrink"> <div class=md-header-nav__source> <a href=https://github.com/larq/larq title="Go to repository" class=md-source data-md-source=github> <div class=md-source__icon> <svg viewbox="0 0 24 24" width=24 height=24> <use xlink:href=#__github width=24 height=24></use> </svg> </div> <div class=md-source__repository> larq/larq </div> </a> </div> </div> </div> </nav> </header> <div class=md-container> <!-- Noop component to simplify sidebar appearence --> <nav class="md-tabs md-tabs--active"></nav> <main class=md-main> <div class="md-main__inner md-grid" data-md-component=container> <div class="md-sidebar md-sidebar--primary" data-md-component=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" data-md-level=0> <label class="md-nav__title md-nav__title--site" for=__drawer> <a href=https://larq.dev/ title=Larq class="md-nav__button md-logo"> <i class=md-icon>developer_board</i> </a> Larq </label> <div class=md-nav__source> <a href=https://github.com/larq/larq title="Go to repository" class=md-source data-md-source=github> <div class=md-source__icon> <svg viewbox="0 0 24 24" width=24 height=24> <use xlink:href=#__github width=24 height=24></use> </svg> </div> <div class=md-source__repository> larq/larq </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-toggle md-nav__toggle" data-md-toggle=nav-1 type=checkbox id=nav-1 checked> <label class=md-nav__link for=nav-1> Learn </label> <nav class=md-nav data-md-component=collapsible data-md-level=1> <label class=md-nav__title for=nav-1> Learn </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. title=Introduction class=md-nav__link> Introduction </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-toggle md-nav__toggle" data-md-toggle=nav-1-2 type=checkbox id=nav-1-2 checked> <label class=md-nav__link for=nav-1-2> User Guides </label> <nav class=md-nav data-md-component=collapsible data-md-level=2> <label class=md-nav__title for=nav-1-2> User Guides </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../key-concepts/ title="Key Concepts" class=md-nav__link> Key Concepts </a> </li> <li class=md-nav__item> <a href=../bnn-architecture/ title="Building BNNs" class=md-nav__link> Building BNNs </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-toggle md-nav__toggle" data-md-toggle=toc type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> Training BNNs </label> <a href=./ title="Training BNNs" class="md-nav__link md-nav__link--active"> Training BNNs </a> <nav class="md-nav md-nav--secondary"> <label class=md-nav__title for=__toc>Table of contents</label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=#the-problem-with-sgd-in-bnns title="The Problem with SGD in BNNs" class=md-nav__link> The Problem with SGD in BNNs </a> </li> <li class=md-nav__item> <a href=#latent-weights title="Latent Weights" class=md-nav__link> Latent Weights </a> <nav class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a href=#alternative-custom-optimizers title="Alternative: Custom Optimizers" class=md-nav__link> Alternative: Custom Optimizers </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#choice-of-pseudo-gradient title="Choice of Pseudo-Gradient" class=md-nav__link> Choice of Pseudo-Gradient </a> </li> <li class=md-nav__item> <a href=#choice-of-optimizer title="Choice of Optimizer" class=md-nav__link> Choice of Optimizer </a> </li> <li class=md-nav__item> <a href=#tips-tricks title="Tips & Tricks" class=md-nav__link> Tips &amp; Tricks </a> </li> <li class=md-nav__item> <a href=#further-references title="Further References" class=md-nav__link> Further References </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-toggle md-nav__toggle" data-md-toggle=nav-1-3 type=checkbox id=nav-1-3> <label class=md-nav__link for=nav-1-3> Examples </label> <nav class=md-nav data-md-component=collapsible data-md-level=2> <label class=md-nav__title for=nav-1-3> Examples </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../examples/mnist/ title="Introduction to BNNs with Larq" class=md-nav__link> Introduction to BNNs with Larq </a> </li> <li class=md-nav__item> <a href=../../examples/binarynet_cifar10/ title="BinaryNet on CIFAR10" class=md-nav__link> BinaryNet on CIFAR10 </a> </li> <li class=md-nav__item> <a href=../../examples/binarynet_advanced_cifar10/ title="BinaryNet on CIFAR10 (Advanced)" class=md-nav__link> BinaryNet on CIFAR10 (Advanced) </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-toggle md-nav__toggle" data-md-toggle=nav-2 type=checkbox id=nav-2> <label class=md-nav__link for=nav-2> API </label> <nav class=md-nav data-md-component=collapsible data-md-level=1> <label class=md-nav__title for=nav-2> API </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../api/layers/ title=Layers class=md-nav__link> Layers </a> </li> <li class=md-nav__item> <a href=../../api/quantizers/ title=Quantizers class=md-nav__link> Quantizers </a> </li> <li class=md-nav__item> <a href=../../api/activations/ title=Activations class=md-nav__link> Activations </a> </li> <li class=md-nav__item> <a href=../../api/constraints/ title=Constraints class=md-nav__link> Constraints </a> </li> <li class=md-nav__item> <a href=../../api/callbacks/ title=Callbacks class=md-nav__link> Callbacks </a> </li> <li class=md-nav__item> <a href=../../api/optimizers/ title=Optimizers class=md-nav__link> Optimizers </a> </li> <li class=md-nav__item> <a href=../../api/math/ title=Math class=md-nav__link> Math </a> </li> <li class=md-nav__item> <a href=../../api/models/ title=Models class=md-nav__link> Models </a> </li> <li class=md-nav__item> <a href=../../api/metrics/ title=Metrics class=md-nav__link> Metrics </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-toggle md-nav__toggle" data-md-toggle=nav-3 type=checkbox id=nav-3> <label class=md-nav__link for=nav-3> Models </label> <nav class=md-nav data-md-component=collapsible data-md-level=1> <label class=md-nav__title for=nav-3> Models </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../models/ title="Larq Zoo" class=md-nav__link> Larq Zoo </a> </li> <li class=md-nav__item> <a href=../../models/examples/ title=Examples class=md-nav__link> Examples </a> </li> <li class=md-nav__item> <a href=../../models/api/ title=API class=md-nav__link> API </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-toggle md-nav__toggle" data-md-toggle=nav-4 type=checkbox id=nav-4> <label class=md-nav__link for=nav-4> Community </label> <nav class=md-nav data-md-component=collapsible data-md-level=1> <label class=md-nav__title for=nav-4> Community </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../papers/ title="Papers using Larq" class=md-nav__link> Papers using Larq </a> </li> <li class=md-nav__item> <a href=../../contributing/ title="Contributing Guide" class=md-nav__link> Contributing Guide </a> </li> <li class=md-nav__item> <a href=../../code-of-conduct/ title="Code of Conduct" class=md-nav__link> Code of Conduct </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-toggle md-nav__toggle" data-md-toggle=nav-5 type=checkbox id=nav-5> <label class=md-nav__link for=nav-5> Why Larq? </label> <nav class=md-nav data-md-component=collapsible data-md-level=1> <label class=md-nav__title for=nav-5> Why Larq? </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../about/ title=About class=md-nav__link> About </a> </li> <li class=md-nav__item> <a href=../../faq/ title=FAQ class=md-nav__link> FAQ </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary"> <label class=md-nav__title for=__toc>Table of contents</label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=#the-problem-with-sgd-in-bnns title="The Problem with SGD in BNNs" class=md-nav__link> The Problem with SGD in BNNs </a> </li> <li class=md-nav__item> <a href=#latent-weights title="Latent Weights" class=md-nav__link> Latent Weights </a> <nav class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a href=#alternative-custom-optimizers title="Alternative: Custom Optimizers" class=md-nav__link> Alternative: Custom Optimizers </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#choice-of-pseudo-gradient title="Choice of Pseudo-Gradient" class=md-nav__link> Choice of Pseudo-Gradient </a> </li> <li class=md-nav__item> <a href=#choice-of-optimizer title="Choice of Optimizer" class=md-nav__link> Choice of Optimizer </a> </li> <li class=md-nav__item> <a href=#tips-tricks title="Tips & Tricks" class=md-nav__link> Tips &amp; Tricks </a> </li> <li class=md-nav__item> <a href=#further-references title="Further References" class=md-nav__link> Further References </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content> <article class="md-content__inner md-typeset"> <h1>Training BNNs</h1> <p>Once you have defined a good architecture for your BNN, you want to train it. Here we give an introduction to common training strategies and tricks that are popular in the field. After reading this guide you should have a good idea of how you can train your BNN.</p> <p>Below we first discuss the fundamental challenges of BNN optimization. We then explain the most commonly used training strategy, of using latent weights, and cover the questions, tips &amp; tricks that tend to come up when training BNNs.</p> <h2 id=the-problem-with-sgd-in-bnns>The Problem with SGD in BNNs<a class=headerlink href=#the-problem-with-sgd-in-bnns title="Permanent link">&para;</a></h2> <p>Stochastic Gradient Descent (SGD) is used pretty much everywhere in the field Deep Learning nowadays - either in its vanilla form or as the core part of some more sophisticated algorithm like <a href=https://arxiv.org/abs/1412.6980>Adam</a>.</p> <p>However, when turning to BNNs, two fundamental issues arise with SGD:</p> <ul> <li>The gradient of the binarization operation is zero almost everywhere, making the gradient <span><span class=MathJax_Preview>\frac{\partial L}{\partial w}</span><script type=math/tex>\frac{\partial L}{\partial w}</script></span> utterly uninformative.</li> <li>SGD performs optimization through small update steps that are accumulated over time. Binary weights, meanwhile, cannot absorb small updates: they can only be left alone, or flipped.</li> </ul> <p>Another way of putting this is that the loss landscape for BNN is very different than what you are used to for real-valued networks. Gone are the glowing hills you can simply glide down from: the loss is now a discrete function, and many of the intuitions and theories developed for continuous loss landscapes no longer apply.</p> <p>Luckily, there has been significant progress in solving these problems. The issue of zero gradients is resolved by replacing the gradient by some more informative alternative, what we call a 'pseudo-gradient'. The issue of updating can be resolved either by introducing latent weights, or by opting for a custom BNN optimizer.</p> <h2 id=latent-weights>Latent Weights<a class=headerlink href=#latent-weights title="Permanent link">&para;</a></h2> <p>Suppose we take a batch of training samples and evaluate a forward and backward pass. During the backward pass we replace the gradients with a pseudo-gradient, and we get a gradient vector on our weights. We then feed this into an optimizer, and get a vector with updates for our weights.</p> <p>At this point, what do we do? If we directly apply the updates to our weights, they are no longer binary. The standard solution to this problem has been to introduce real-valued <strong>latent weights</strong>. We apply our update step to this real-valued weight. During the forward pass, we use the binarized version of the latent weight.</p> <p>Beware that latent weights are <a href=https://arxiv.org/abs/1906.02107>not really weights at all</a> - after all, changing the latent weights usually doesn't affect the behavior of the network and we throw the latent weights away after we're done training. Instead, they are best thought of as a product between the weight and a positive inertia: the higher this inertia, the stronger the signal required to make the weight flip.</p> <p>One implication of this is that the latent weights should be constrained: as an increase in inertia does not change the behavior of the network, it can otherwise grow indefinitely.</p> <p>In Larq, it is trivial to implement this strategy. An example of a layer optimized with this method would look like:</p> <div class=codehilite><pre><span></span><span class=n>x_out</span> <span class=o>=</span> <span class=n>larq</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>QuantDense</span><span class=p>(</span><span class=mi>512</span><span class=p>,</span>
                               <span class=n>input_qunatizer</span><span class=o>=</span><span class=s2>&quot;ste_sign&quot;</span><span class=p>,</span>
                               <span class=n>kernel_quantizer</span><span class=o>=</span><span class=s2>&quot;ste_sign&quot;</span><span class=p>,</span>
                               <span class=n>kernel_constraint</span><span class=o>=</span><span class=s2>&quot;weight_clip&quot;</span><span class=p>)(</span><span class=n>x_out</span><span class=p>)</span>
</pre></div> <p>Any optimizer you now apply will update the latent weights; after the update the latent weights are clipped to <span><span class=MathJax_Preview>[-1, 1]</span><script type=math/tex>[-1, 1]</script></span>.</p> <h3 id=alternative-custom-optimizers>Alternative: Custom Optimizers<a class=headerlink href=#alternative-custom-optimizers title="Permanent link">&para;</a></h3> <p>Instead of using latent weights, one can opt for a custom BNN optimizer that inherently generates binary weights. An example of such an optimizer is <a href=api/optimizers/#bop>Bop</a>.</p> <h2 id=choice-of-pseudo-gradient>Choice of Pseudo-Gradient<a class=headerlink href=#choice-of-pseudo-gradient title="Permanent link">&para;</a></h2> <p>In <a href=/api/quantizers><code>larq.quantizers</code></a> you will find a variety of quantizers that have been introduced in different papers. Many of these quantizers behave identically during the forward pass but implement different pseudo-gradients. Studies comparing different pseudo-gradients report little difference between them. Therefore, we recommend using the classical <a href=/api/quantizers/#ste_sign><code>ste_sign()</code></a> as default.</p> <h2 id=choice-of-optimizer>Choice of Optimizer<a class=headerlink href=#choice-of-optimizer title="Permanent link">&para;</a></h2> <p>When using a latent weight strategy, you can apply any optimizer you are familiar with from real-valued deep learning. However, due the different nature of BNNs your intuitions may be off. We recommend using Adam: although other optimizers can achieve similar accuracies with a lot of finetuning, we and others have found that Adam is the quickest to converge and the least sensitive to the choice of hyperparamters .</p> <h2 id=tips-tricks>Tips &amp; Tricks<a class=headerlink href=#tips-tricks title="Permanent link">&para;</a></h2> <p>Here are some general tips and tricks that you may want to keep in mind:</p> <ul> <li>BNN training is more noisy due to non-continuous nature of flipping weights; therefore, we recommend setting your batch norm momentum to 0.9.</li> <li>Beware that BNNs tend to require many more epochs than real-valued networks to converge: 200+ epochs when training an AlexNet or ResNet-18 style network on ImageNet is not unusual.</li> <li>Networks tend to train much quicker if they are initialized from a trained real-valued model. Importantly, this requires the overall architecture of the pretrained network to be as similar as possible to the BNN, including placement of the activation operation (which replaces the binarization operation). Note that although convergence is faster, pretraining does not seem to improve final accuracy.</li> </ul> <h2 id=further-references>Further References<a class=headerlink href=#further-references title="Permanent link">&para;</a></h2> <p>If you would like to learn more, we recommend checking out the following papers (starting at the most recent):</p> <ul> <li><a href=https://arxiv.org/abs/1906.02107>Latent Weights Do Not Exist: Rethinking Binarized Neural Network Optimization</a> - This paper investigates optimization of BNNs using latent weights and introduces <a href=/api/optimizers/#bop>Bop</a> as the first custom BNN optimizer.</li> <li><a href="https://openreview.net/forum?id=rJfUCoR5KX">An Empirical study of Binary Neural Networks' Optimisation</a> - An empirical comparison of BNN optimization methods, including a detailed discussion on the use of various optimizers and a number of tricks used in the literature.</li> </ul> </article> </div> </div> </main> <footer class=md-footer> <div class=md-footer-nav> <nav class="md-footer-nav__inner md-grid"> <a href=../bnn-architecture/ title="Building BNNs" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel=prev> <div class="md-flex__cell md-flex__cell--shrink"> <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i> </div> <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title"> <span class=md-flex__ellipsis> <span class=md-footer-nav__direction> Previous </span> Building BNNs </span> </div> </a> <a href=../../examples/mnist/ title="Introduction to BNNs with Larq" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel=next> <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title"> <span class=md-flex__ellipsis> <span class=md-footer-nav__direction> Next </span> Introduction to BNNs with Larq </span> </div> <div class="md-flex__cell md-flex__cell--shrink"> <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i> </div> </a> </nav> </div> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-footer-copyright> powered by <a href=https://www.mkdocs.org>MkDocs</a> and <a href=https://squidfunk.github.io/mkdocs-material/ > Material for MkDocs</a> </div> <div class=md-footer-social> <link rel=stylesheet href=../../assets/fonts/font-awesome.css> <a href=https://github.com/larq class="md-footer-social__link fa fa-github"></a> <a href=https://twitter.com/PlumeraiHQ class="md-footer-social__link fa fa-twitter"></a> <a href=https://www.linkedin.com/company/plumerai/ class="md-footer-social__link fa fa-linkedin"></a> </div> </div> </div> </footer> </div> <script src=../../assets/javascripts/application.245445c6.js></script> <script>app.initialize({version:"1.0.4",url:{base:"../.."}})</script> <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_CHTML"></script> <script src=https://cdn.jsdelivr.net/npm/vega@5></script> <script src=https://cdn.jsdelivr.net/npm/vega-lite@3></script> <script src=https://cdn.jsdelivr.net/npm/vega-embed@4></script> </body> </html>
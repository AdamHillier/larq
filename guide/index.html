<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="ie=edge"><meta name=description content="An Open Source Machine Learning Framework for Training Extreme Quantized Neural Networks"><link href=https://larq.dev/guide/ rel=canonical><meta name=author content=Plumerai><meta name=lang:clipboard.copy content="Copy to clipboard"><meta name=lang:clipboard.copied content="Copied to clipboard"><meta name=lang:search.language content=en><meta name=lang:search.pipeline.stopwords content=True><meta name=lang:search.pipeline.trimmer content=True><meta name=lang:search.result.none content="No matching documents"><meta name=lang:search.result.one content="1 matching document"><meta name=lang:search.result.other content="# matching documents"><meta name=lang:search.tokenizer content=[\s\-]+><link rel="shortcut icon" href=../assets/images/favicon.png><meta name=generator content="mkdocs-1.0.4, mkdocs-material-4.4.0"><title>User Guide - Larq</title><link rel=stylesheet href=../assets/stylesheets/application.0284f74d.css><link rel=stylesheet href=../assets/stylesheets/application-palette.01803549.css><meta name=theme-color content=#2196f3><script src=../assets/javascripts/modernizr.74668098.js></script><link href=https://fonts.gstatic.com rel=preconnect crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono&display=fallback"><style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style><link rel=stylesheet href=../assets/fonts/material-icons.css><link rel=stylesheet href=../custom.css></head> <body dir=ltr data-md-color-primary=blue data-md-color-accent=blue> <svg class=md-svg> <defs> <svg xmlns=http://www.w3.org/2000/svg width=416 height=448 viewbox="0 0 416 448" id=__github><path fill=currentColor d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg> </defs> </svg> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay data-md-component=overlay for=__drawer></label> <a href=#user-guide tabindex=1 class=md-skip> Skip to content </a> <header class=md-header data-md-component=header> <nav class="md-header-nav md-grid"> <div class=md-flex> <div class="md-flex__cell md-flex__cell--shrink"> <a href=https://larq.dev/ title=Larq class="md-header-nav__button md-logo"> <i class=md-icon>developer_board</i> </a> </div> <div class="md-flex__cell md-flex__cell--shrink"> <label class="md-icon md-icon--menu md-header-nav__button" for=__drawer></label> </div> <div class="md-flex__cell md-flex__cell--stretch"> <div class="md-flex__ellipsis md-header-nav__title" data-md-component=title> <span class=md-header-nav__topic> Larq </span> <span class=md-header-nav__topic> User Guide </span> </div> </div> <div class="md-flex__cell md-flex__cell--shrink"> <label class="md-icon md-icon--search md-header-nav__button" for=__search></label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=query data-md-state=active> <label class="md-icon md-search__icon" for=__search></label> <button type=reset class="md-icon md-search__icon" data-md-component=reset tabindex=-1> &#xE5CD; </button> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=result> <div class=md-search-result__meta> Type to start searching </div> <ol class=md-search-result__list></ol> </div> </div> </div> </div> </div> </div> <div class="md-flex__cell md-flex__cell--shrink"> <div class=md-header-nav__source> <a href=https://github.com/plumerai/larq title="Go to repository" class=md-source data-md-source=github> <div class=md-source__icon> <svg viewbox="0 0 24 24" width=24 height=24> <use xlink:href=#__github width=24 height=24></use> </svg> </div> <div class=md-source__repository> plumerai/larq </div> </a> </div> </div> </div> </nav> </header> <div class=md-container> <nav class="md-tabs md-tabs--active" data-md-component=tabs> <div class="md-tabs__inner md-grid"> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=.. title=Learn class="md-tabs__link md-tabs__link--active"> Learn </a> </li> <li class=md-tabs__item> <a href=../examples/mnist/ title=Tutorials class=md-tabs__link> Tutorials </a> </li> <li class=md-tabs__item> <a href=../api/layers/ title=API class=md-tabs__link> API </a> </li> <li class=md-tabs__item> <a href=../papers/ title=Community class=md-tabs__link> Community </a> </li> </ul> </div> </nav> <main class=md-main> <div class="md-main__inner md-grid" data-md-component=container> <div class="md-sidebar md-sidebar--primary" data-md-component=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" data-md-level=0> <label class="md-nav__title md-nav__title--site" for=__drawer> <a href=https://larq.dev/ title=Larq class="md-nav__button md-logo"> <i class=md-icon>developer_board</i> </a> Larq </label> <div class=md-nav__source> <a href=https://github.com/plumerai/larq title="Go to repository" class=md-source data-md-source=github> <div class=md-source__icon> <svg viewbox="0 0 24 24" width=24 height=24> <use xlink:href=#__github width=24 height=24></use> </svg> </div> <div class=md-source__repository> plumerai/larq </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-toggle md-nav__toggle" data-md-toggle=nav-1 type=checkbox id=nav-1 checked> <label class=md-nav__link for=nav-1> Learn </label> <nav class=md-nav data-md-component=collapsible data-md-level=1> <label class=md-nav__title for=nav-1> Learn </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=.. title=Introduction class=md-nav__link> Introduction </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-toggle md-nav__toggle" data-md-toggle=toc type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> User Guide </label> <a href=./ title="User Guide" class="md-nav__link md-nav__link--active"> User Guide </a> <nav class="md-nav md-nav--secondary"> <label class=md-nav__title for=__toc>Table of contents</label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=#using-custom-quantizers title="Using Custom Quantizers" class=md-nav__link> Using Custom Quantizers </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-toggle md-nav__toggle" data-md-toggle=nav-2 type=checkbox id=nav-2> <label class=md-nav__link for=nav-2> Tutorials </label> <nav class=md-nav data-md-component=collapsible data-md-level=1> <label class=md-nav__title for=nav-2> Tutorials </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../examples/mnist/ title="Introduction to BNNs with Larq" class=md-nav__link> Introduction to BNNs with Larq </a> </li> <li class=md-nav__item> <a href=../examples/binarynet_cifar10/ title="BinaryNet on CIFAR10" class=md-nav__link> BinaryNet on CIFAR10 </a> </li> <li class=md-nav__item> <a href=../examples/binarynet_advanced_cifar10/ title="BinaryNet on CIFAR10 (Advanced)" class=md-nav__link> BinaryNet on CIFAR10 (Advanced) </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-toggle md-nav__toggle" data-md-toggle=nav-3 type=checkbox id=nav-3> <label class=md-nav__link for=nav-3> API </label> <nav class=md-nav data-md-component=collapsible data-md-level=1> <label class=md-nav__title for=nav-3> API </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../api/layers/ title=Layers class=md-nav__link> Layers </a> </li> <li class=md-nav__item> <a href=../api/quantizers/ title=Quantizers class=md-nav__link> Quantizers </a> </li> <li class=md-nav__item> <a href=../api/activations/ title=Activations class=md-nav__link> Activations </a> </li> <li class=md-nav__item> <a href=../api/constraints/ title=Constraints class=md-nav__link> Constraints </a> </li> <li class=md-nav__item> <a href=../api/callbacks/ title=Callbacks class=md-nav__link> Callbacks </a> </li> <li class=md-nav__item> <a href=../api/optimizers/ title=Optimizers class=md-nav__link> Optimizers </a> </li> <li class=md-nav__item> <a href=../api/math/ title=Math class=md-nav__link> Math </a> </li> <li class=md-nav__item> <a href=../api/models/ title=Models class=md-nav__link> Models </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-toggle md-nav__toggle" data-md-toggle=nav-4 type=checkbox id=nav-4> <label class=md-nav__link for=nav-4> Community </label> <nav class=md-nav data-md-component=collapsible data-md-level=1> <label class=md-nav__title for=nav-4> Community </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../papers/ title="Papers using Larq" class=md-nav__link> Papers using Larq </a> </li> <li class=md-nav__item> <a href=../contributing/ title="Contributing Guide" class=md-nav__link> Contributing Guide </a> </li> <li class=md-nav__item> <a href=../code_of_conduct/ title="Code of Conduct" class=md-nav__link> Code of Conduct </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary"> <label class=md-nav__title for=__toc>Table of contents</label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=#using-custom-quantizers title="Using Custom Quantizers" class=md-nav__link> Using Custom Quantizers </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content> <article class="md-content__inner md-typeset"> <h1 id=user-guide>User Guide<a class=headerlink href=#user-guide title="Permanent link">&para;</a></h1> <p>To build a Quantized Neural Network (QNN), Larq introduces the concept of <a href=https://larq.dev/api/layers/ >quantized layers</a> and <a href=https://larq.dev/api/quantizers/ >quantizers</a>. A quantizer defines the way of transforming a full precision input to a quantized output and the pseudo-gradient method used for the backwards pass.</p> <p>Each quantized layer requires an <code>input_quantizer</code> and a <code>kernel_quantizer</code> that describe the way of quantizing the incoming activations and weights of the layer respectively. If both <code>input_quantizer</code> and <code>kernel_quantizer</code> are <code>None</code> the layer is equivalent to a full precision layer.</p> <p>A quantized layer computes</p> <p>\[ \sigma(f(q_{\, \mathrm{kernel}}(\boldsymbol{w}), q_{\, \mathrm{input}}(\boldsymbol{x})) + b) \]</p> <p>with full precision weights <span><span class=MathJax_Preview>\boldsymbol{w}</span><script type=math/tex>\boldsymbol{w}</script></span>, arbitrary precision input <span><span class=MathJax_Preview>\boldsymbol{x}</span><script type=math/tex>\boldsymbol{x}</script></span>, layer operation <span><span class=MathJax_Preview>f</span><script type=math/tex>f</script></span> (e.g. <span><span class=MathJax_Preview>f(\boldsymbol{w}, \boldsymbol{x}) = \boldsymbol{x}^T \boldsymbol{w}</span><script type=math/tex>f(\boldsymbol{w}, \boldsymbol{x}) = \boldsymbol{x}^T \boldsymbol{w}</script></span> for a densely-connected layer), activation <span><span class=MathJax_Preview>\sigma</span><script type=math/tex>\sigma</script></span> and bias <span><span class=MathJax_Preview>b</span><script type=math/tex>b</script></span>. This will result in the following computational graph:</p> <div style=text-align:center;> <svg width=50% viewbox="0 0 249 238" fill=none xmlns=http://www.w3.org/2000/svg> <rect width=249 height=238 fill=white /> <rect x=151 y=6 width=67 height=22 fill=#3F51B5 /> <text fill=white xml:space=preserve style="white-space: pre" font-family="Roboto Mono" font-size=12 letter-spacing=0em><tspan x=162.27 y=21.1016>kernel</tspan></text> <rect x=162 y=127 width=67 height=22 fill=#3F51B5 /> <text fill=white xml:space=preserve style="white-space: pre" font-family="Roboto Mono" font-size=12 letter-spacing=0em><tspan x=180.477 y=142.102>bias</tspan></text> <rect x=28 y=7 width=67 height=21 fill=#2196F3 /> <text fill=white xml:space=preserve style="white-space: pre" font-family="Roboto Mono" font-size=12 letter-spacing=0em><tspan x=43.4824 y=21.1016>input</tspan></text> <rect x=90 y=209 width=67 height=21 fill=#2196F3 /> <text fill=white xml:space=preserve style="white-space: pre" font-family="Roboto Mono" font-size=12 letter-spacing=0em><tspan x=101.879 y=223.102>output</tspan></text> <text fill=black fill-opacity=0.54 xml:space=preserve style="white-space: pre" font-family="Roboto Mono" font-size=12 letter-spacing=0em><tspan x=7.44727 y=64.1016>input_quantizer</tspan></text> <text fill=black fill-opacity=0.54 xml:space=preserve style="white-space: pre" font-family="Roboto Mono" font-size=12 letter-spacing=0em><tspan x=126.844 y=64.1016>kernel_quantizer</tspan></text> <text fill=black fill-opacity=0.54 xml:space=preserve style="white-space: pre" font-family="Roboto Mono" font-size=12 letter-spacing=0em><tspan x=69.4473 y=103.102>layer_operation</tspan></text> <text fill=black fill-opacity=0.54 xml:space=preserve style="white-space: pre" font-family="Roboto Mono" font-size=12 letter-spacing=0em><tspan x=112.689 y=142.102>add</tspan></text> <text fill=black fill-opacity=0.54 xml:space=preserve style="white-space: pre" font-family="Roboto Mono" font-size=12 letter-spacing=0em><tspan x=87.4648 y=181.102>activation</tspan></text> <path fill=black fill-opacity=0.54 d="M60.6464 48.3536C60.8417 48.5488 61.1583 48.5488 61.3536 48.3536L64.5355 45.1716C64.7308 44.9763 64.7308 44.6597 64.5355 44.4645C64.3403 44.2692 64.0237 44.2692 63.8284 44.4645L61 47.2929L58.1716 44.4645C57.9763 44.2692 57.6597 44.2692 57.4645 44.4645C57.2692 44.6597 57.2692 44.9763 57.4645 45.1716L60.6464 48.3536ZM60.5 32V48H61.5V32H60.5Z"/> <path fill=black fill-opacity=0.54 d="M183.646 48.3536C183.842 48.5488 184.158 48.5488 184.354 48.3536L187.536 45.1716C187.731 44.9763 187.731 44.6597 187.536 44.4645C187.34 44.2692 187.024 44.2692 186.828 44.4645L184 47.2929L181.172 44.4645C180.976 44.2692 180.66 44.2692 180.464 44.4645C180.269 44.6597 180.269 44.9763 180.464 45.1716L183.646 48.3536ZM183.5 32V48H184.5V32H183.5Z"/> <path fill=black fill-opacity=0.54 d="M123.646 204.354C123.842 204.549 124.158 204.549 124.354 204.354L127.536 201.172C127.731 200.976 127.731 200.66 127.536 200.464C127.34 200.269 127.024 200.269 126.828 200.464L124 203.293L121.172 200.464C120.976 200.269 120.66 200.269 120.464 200.464C120.269 200.66 120.269 200.976 120.464 201.172L123.646 204.354ZM123.5 188V204H124.5V188H123.5Z"/> <path fill=black fill-opacity=0.54 d="M123.646 165.354C123.842 165.549 124.158 165.549 124.354 165.354L127.536 162.172C127.731 161.976 127.731 161.66 127.536 161.464C127.34 161.269 127.024 161.269 126.828 161.464L124 164.293L121.172 161.464C120.976 161.269 120.66 161.269 120.464 161.464C120.269 161.66 120.269 161.976 120.464 162.172L123.646 165.354ZM123.5 149V165H124.5V149H123.5Z"/> <path fill=black fill-opacity=0.54 d="M123.646 126.354C123.842 126.549 124.158 126.549 124.354 126.354L127.536 123.172C127.731 122.976 127.731 122.66 127.536 122.464C127.34 122.269 127.024 122.269 126.828 122.464L124 125.293L121.172 122.464C120.976 122.269 120.66 122.269 120.464 122.464C120.269 122.66 120.269 122.976 120.464 123.172L123.646 126.354ZM123.5 110V126H124.5V110H123.5Z"/> <path fill=black fill-opacity=0.54 d="M140.624 137.647C140.441 137.842 140.461 138.158 140.669 138.353L144.049 141.529C144.256 141.724 144.573 141.724 144.756 141.529C144.939 141.334 144.919 141.018 144.712 140.823L141.707 138L144.359 135.177C144.542 134.982 144.522 134.666 144.315 134.471C144.108 134.276 143.791 134.276 143.608 134.471L140.624 137.647ZM157 137.501L140.969 137.501L141.031 138.499L157.062 138.499L157 137.501Z"/> <path fill=black fill-opacity=0.54 d="M150.5 85.3137C150.5 85.5899 150.724 85.8137 151 85.8137H155.5C155.776 85.8137 156 85.5899 156 85.3137C156 85.0376 155.776 84.8137 155.5 84.8137H151.5V80.8137C151.5 80.5376 151.276 80.3137 151 80.3137C150.724 80.3137 150.5 80.5376 150.5 80.8137L150.5 85.3137ZM161.96 73.6464L150.646 84.9602L151.354 85.6673L162.667 74.3536L161.96 73.6464Z"/> <path fill=black fill-opacity=0.54 d="M97.3137 85.8137C97.5899 85.8137 97.8137 85.5899 97.8137 85.3137V80.8137C97.8137 80.5376 97.5899 80.3137 97.3137 80.3137C97.0376 80.3137 96.8137 80.5376 96.8137 80.8137V84.8137H92.8137C92.5376 84.8137 92.3137 85.0376 92.3137 85.3137C92.3137 85.5899 92.5376 85.8137 92.8137 85.8137H97.3137ZM85.6464 74.3536L96.9602 85.6673L97.6673 84.9602L86.3536 73.6464L85.6464 74.3536Z"/> </svg> </div> <p>Larq layers are fully compatible with the Keras API so you can use them with Keras Layers interchangeably:</p> <div class=superfences-tabs> <input name=__tabs_1 type=radio id=__tab_1_0 checked=checked> <label for=__tab_1_0>Larq 32-bit model</label> <div class=superfences-content><div class=codehilite><pre><span></span><span class=n>model</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>models</span><span class=o>.</span><span class=n>Sequential</span><span class=p>([</span>
    <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>Flatten</span><span class=p>(),</span>
    <span class=n>larq</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>QuantDense</span><span class=p>(</span><span class=mi>512</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s2>&quot;relu&quot;</span><span class=p>),</span>
    <span class=n>larq</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>QuantDense</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s2>&quot;softmax&quot;</span><span class=p>)</span>
<span class=p>])</span>
</pre></div></div> <input name=__tabs_1 type=radio id=__tab_1_1> <label for=__tab_1_1>Keras 32-bit model</label> <div class=superfences-content><div class=codehilite><pre><span></span><span class=n>model</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>models</span><span class=o>.</span><span class=n>Sequential</span><span class=p>([</span>
    <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>Flatten</span><span class=p>(),</span>
    <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>Dense</span><span class=p>(</span><span class=mi>512</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s2>&quot;relu&quot;</span><span class=p>),</span>
    <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>Dense</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s2>&quot;softmax&quot;</span><span class=p>)</span>
<span class=p>])</span>
</pre></div></div> </div> <p>A simple fully-connected Binarized Neural Network (BNN) using the <a href=https://larq.dev/api/quantizers/#ste_sign>Straight-Through Estimator</a> can be defined in just a few lines of code using either the Keras sequential, functional or model subclassing APIs:</p> <div class=superfences-tabs> <input name=__tabs_2 type=radio id=__tab_2_0 checked=checked> <label for=__tab_2_0>Larq 1-bit model</label> <div class=superfences-content><div class=codehilite><pre><span></span><span class=n>model</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>models</span><span class=o>.</span><span class=n>Sequential</span><span class=p>([</span>
    <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>Flatten</span><span class=p>(),</span>
    <span class=n>larq</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>QuantDense</span><span class=p>(</span><span class=mi>512</span><span class=p>,</span>
                           <span class=n>kernel_quantizer</span><span class=o>=</span><span class=s2>&quot;ste_sign&quot;</span><span class=p>,</span>
                           <span class=n>kernel_constraint</span><span class=o>=</span><span class=s2>&quot;weight_clip&quot;</span><span class=p>),</span>
    <span class=n>larq</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>QuantDense</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span>
                           <span class=n>input_quantizer</span><span class=o>=</span><span class=s2>&quot;ste_sign&quot;</span><span class=p>,</span>
                           <span class=n>kernel_quantizer</span><span class=o>=</span><span class=s2>&quot;ste_sign&quot;</span><span class=p>,</span>
                           <span class=n>kernel_constraint</span><span class=o>=</span><span class=s2>&quot;weight_clip&quot;</span><span class=p>,</span>
                           <span class=n>activation</span><span class=o>=</span><span class=s2>&quot;softmax&quot;</span><span class=p>)])</span>
</pre></div></div> <input name=__tabs_2 type=radio id=__tab_2_1> <label for=__tab_2_1>Larq 1-bit model functional</label> <div class=superfences-content><div class=codehilite><pre><span></span><span class=n>x</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>Input</span><span class=p>(</span><span class=n>shape</span><span class=o>=</span><span class=p>(</span><span class=mi>28</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>1</span><span class=p>))</span>
<span class=n>y</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>Flatten</span><span class=p>()(</span><span class=n>x</span><span class=p>)</span>
<span class=n>y</span> <span class=o>=</span> <span class=n>larq</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>QuantDense</span><span class=p>(</span><span class=mi>512</span><span class=p>,</span>
                           <span class=n>kernel_quantizer</span><span class=o>=</span><span class=s2>&quot;ste_sign&quot;</span><span class=p>,</span>
                           <span class=n>kernel_constraint</span><span class=o>=</span><span class=s2>&quot;weight_clip&quot;</span><span class=p>)(</span><span class=n>y</span><span class=p>)</span>
<span class=n>y</span> <span class=o>=</span> <span class=n>larq</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>QuantDense</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span>
                           <span class=n>input_quantizer</span><span class=o>=</span><span class=s2>&quot;ste_sign&quot;</span><span class=p>,</span>
                           <span class=n>kernel_quantizer</span><span class=o>=</span><span class=s2>&quot;ste_sign&quot;</span><span class=p>,</span>
                           <span class=n>kernel_constraint</span><span class=o>=</span><span class=s2>&quot;weight_clip&quot;</span><span class=p>,</span>
                           <span class=n>activation</span><span class=o>=</span><span class=s2>&quot;softmax&quot;</span><span class=p>)(</span><span class=n>y</span><span class=p>)</span>
<span class=n>model</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>Model</span><span class=p>(</span><span class=n>inputs</span><span class=o>=</span><span class=n>x</span><span class=p>,</span> <span class=n>outputs</span><span class=o>=</span><span class=n>y</span><span class=p>)</span>
</pre></div></div> <input name=__tabs_2 type=radio id=__tab_2_2> <label for=__tab_2_2>Larq 1-bit model subclassing</label> <div class=superfences-content><div class=codehilite><pre><span></span><span class=k>class</span> <span class=nc>MyModel</span><span class=p>(</span><span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>Model</span><span class=p>):</span>
    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>flatten</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>Flatten</span><span class=p>()</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>dense1</span> <span class=o>=</span> <span class=n>larq</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>QuantDense</span><span class=p>(</span><span class=mi>512</span><span class=p>,</span>
                                             <span class=n>kernel_quantizer</span><span class=o>=</span><span class=s2>&quot;ste_sign&quot;</span><span class=p>,</span>
                                             <span class=n>kernel_constraint</span><span class=o>=</span><span class=s2>&quot;weight_clip&quot;</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>dense2</span> <span class=o>=</span> <span class=n>larq</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>QuantDense</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span>
                                             <span class=n>input_quantizer</span><span class=o>=</span><span class=s2>&quot;ste_sign&quot;</span><span class=p>,</span>
                                             <span class=n>kernel_quantizer</span><span class=o>=</span><span class=s2>&quot;ste_sign&quot;</span><span class=p>,</span>
                                             <span class=n>kernel_constraint</span><span class=o>=</span><span class=s2>&quot;weight_clip&quot;</span><span class=p>,</span>
                                             <span class=n>activation</span><span class=o>=</span><span class=s2>&quot;softmax&quot;</span><span class=p>)</span>

    <span class=k>def</span> <span class=nf>call</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>inputs</span><span class=p>):</span>
        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>flatten</span><span class=p>(</span><span class=n>inputs</span><span class=p>)</span>
        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>dense1</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>dense2</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>

<span class=n>model</span> <span class=o>=</span> <span class=n>MyModel</span><span class=p>()</span>
</pre></div></div> </div> <h2 id=using-custom-quantizers>Using Custom Quantizers<a class=headerlink href=#using-custom-quantizers title="Permanent link">&para;</a></h2> <p>Quantizers are functions that transform a full precision input to a quantized output. Since this transformation usually is non-differentiable it is necessary to modify the gradient in order to be able to train the resulting QNN. This can be done with the <a href=https://www.tensorflow.org/api_docs/python/tf/custom_gradient><code>tf.custom_gradient</code></a> decorator.</p> <p>In this example we will define a binarization function with an identity gradient:</p> <div class=codehilite><pre><span></span><span class=nd>@tf.custom_gradient</span>
<span class=k>def</span> <span class=nf>identity_sign</span><span class=p>(</span><span class=n>x</span><span class=p>):</span>
    <span class=k>def</span> <span class=nf>grad</span><span class=p>(</span><span class=n>dy</span><span class=p>):</span>
        <span class=k>return</span> <span class=n>dy</span>
    <span class=k>return</span> <span class=n>tf</span><span class=o>.</span><span class=n>sign</span><span class=p>(</span><span class=n>x</span><span class=p>),</span> <span class=n>grad</span>
</pre></div> <p>This function can now be used as an <code>input_quantizer</code> or a <code>kernel_quantizer</code>:</p> <div class=codehilite><pre><span></span><span class=n>larq</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>QuantDense</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span>
                       <span class=n>input_quantizer</span><span class=o>=</span><span class=n>identity_sign</span><span class=p>,</span>
                       <span class=n>kernel_quantizer</span><span class=o>=</span><span class=n>identity_sign</span><span class=p>)</span>
</pre></div> </article> </div> </div> </main> <footer class=md-footer> <div class=md-footer-nav> <nav class="md-footer-nav__inner md-grid"> <a href=.. title=Introduction class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel=prev> <div class="md-flex__cell md-flex__cell--shrink"> <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i> </div> <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title"> <span class=md-flex__ellipsis> <span class=md-footer-nav__direction> Previous </span> Introduction </span> </div> </a> <a href=../examples/mnist/ title="Introduction to BNNs with Larq" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel=next> <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title"> <span class=md-flex__ellipsis> <span class=md-footer-nav__direction> Next </span> Introduction to BNNs with Larq </span> </div> <div class="md-flex__cell md-flex__cell--shrink"> <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i> </div> </a> </nav> </div> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-footer-copyright> powered by <a href=https://www.mkdocs.org>MkDocs</a> and <a href=https://squidfunk.github.io/mkdocs-material/ > Material for MkDocs</a> </div> <div class=md-footer-social> <link rel=stylesheet href=../assets/fonts/font-awesome.css> <a href=https://github.com/plumerai class="md-footer-social__link fa fa-github"></a> <a href=https://twitter.com/PlumeraiHQ class="md-footer-social__link fa fa-twitter"></a> <a href=https://www.linkedin.com/company/plumerai/ class="md-footer-social__link fa fa-linkedin"></a> </div> </div> </div> </footer> </div> <script src=../assets/javascripts/application.245445c6.js></script> <script>app.initialize({version:"1.0.4",url:{base:".."}})</script> <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_CHTML"></script> </body> </html>